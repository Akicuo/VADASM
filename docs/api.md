# API Reference\n\n## Core Classes\n\n### `VADASMMerger`\n\nMain merger class implementing the 5-step V-ADASM pipeline.\n\n```python\nfrom vadasm import VADASMMerger, ModelConfig, MergeConfig\n\nmerger = VADASMMerger(MergeConfig())\nmerged = merger.merge_models(small_config, large_config)\n```\n\n### `ModelConfig` \n\nConfiguration for input models.\n\n**Parameters:**\n- `name_or_path`: Model identifier or local path\n- `hidden_dim`: Hidden dimension \n- `num_layers`: Number of layers\n- `is_moe`: Whether model uses MoE\n- `has_vision`: Whether model has vision capabilities\n\n### `MergeConfig`\n\nV-ADASM merge hyperparameters.\n\n**Key Parameters:**\n- `fusion_beta`: Weight for vision deltas (0.1-0.6)\n- `svd_rank`: SVD variance threshold (0.9-0.99)\n- `ties_drop_rate`: TIES sparsification (0.1-0.5)\n- `evo_generations`: Evolutionary optimization rounds\n\n## Utility Functions\n\n### Model Merging Algorithms\n\n- `ties_merge()`: TIES parameter conflict resolution\n- `dare_merge()`: DARE sparsification \n- `hungarian_neuron_alignment()`: Neuron permutation alignment\n- `svd_subspace_reduction()`: Subspace dimensionality reduction\n\n### Evolutionary Optimization\n\n```python\nfrom vadasm.evolution import EvolutionaryTuner\n\ntuner = EvolutionaryTuner(population_size=50, generations=20)\nbest_params = tuner.optimize_hyperparameters(objective_func, param_bounds)\n```